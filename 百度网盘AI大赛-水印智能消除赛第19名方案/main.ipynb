{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 百度网盘AI大赛-图像处理挑战赛：水印智能消除赛\n",
    "\n",
    "本项目基于[Baseline](https://aistudio.baidu.com/aistudio/projectdetail/3859316?channelType=0&channel=0)使用略作修改的UNet消除图像中水印以完成百度网盘AI大赛-图像处理挑战赛：水印智能消除赛。\n",
    "\n",
    "[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/209/0/introduction)\n",
    "\n",
    "## 比赛介绍\n",
    "日常生活中带有水印的图片很常见，即使是PS专家，也很难快速且不留痕迹的去除水印。而使用智能去除水印的算法，可以快速自动去除图片中的水印。选手需要通过深度学习技术训练模型，对给定的真实场景下采集得到的带有水印的图片进行处理，并最终输出处理后的扫描结果图片。\n",
    "\n",
    "本次比赛希望选手结合当下前沿的图像处理技术与计算机视觉技术，提升模型的训练性能和泛化能力，在保证效果精准的同时，注意模型在实际应用中的性能问题，做到尽可能的小而快。\n",
    "\n",
    "### 评价标准\n",
    "- 评价指标为 PSNR 和 MSSSIM；\n",
    "- 用于评价的机器环境仅提供两种框架模型运行环境：paddlepaddle 和 onnxruntime，其他框架模型可转换为上述两种框架的模型；\n",
    "- 机器配置：V100，显存15G，内存10G；\n",
    "- 单张图片耗时>1.2s，决赛中的性能分数记0分。\n",
    "\n",
    "因此，应尽可能不能使用过大的模型。\n",
    "\n",
    "## 方法介绍\n",
    "在Baseline基础上，本项目继续使用UNet网络，对水印图像进行像素级转换。相比较于Baseline，我们做了四处修改：第一、我们选择使用leaky_relu，而不是relu，以尽可能的保留像素信息；第二、在Encoder与Decoder中间的过渡层，我们不是使用原来的单分支，而是以注意力为权重，建立双分支通路，将自适应加权结果变换后输入到Decoder中，增强模型容量；第三、同样地，水印输出，我们选择双分支输出，以注意力值为权重，增强样本适应性；第四，我们引入网络输入与输出之间的残差连接，着重于网络学习真实图片与水印图片之间的差异，加快了模型收敛。因此在一个压缩包的数据训练下，我们从A榜的0.58307提升到了0.61742。然后我们使用5倍更多的数据进行模型训练，与少量数据训练一致，模型收敛很快，但性能仅仅提升到了0.61805。应该模型本身容量不足以及resize成512x512训练预测导致图片损失大量信息，但没有时间继续调整优化了。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 代码部分\n",
    "## 数据解压\n",
    "这里使用了四个压缩包的数据，其实1个应该就足够了，或者按照比赛学习资料自动生成水印数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T02:47:44.877854Z",
     "iopub.status.busy": "2022-05-17T02:47:44.877187Z",
     "iopub.status.idle": "2022-05-17T02:47:45.571065Z",
     "shell.execute_reply": "2022-05-17T02:47:45.569924Z",
     "shell.execute_reply.started": "2022-05-17T02:47:44.877811Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data\n",
      "/home/aistudio/data/train\n",
      "/home/aistudio\n"
     ]
    }
   ],
   "source": [
    "%cd data\n",
    "!mkdir train\n",
    "%cd train/\n",
    "!mkdir image\n",
    "!mkdir mask\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T02:47:48.230862Z",
     "iopub.status.busy": "2022-05-17T02:47:48.229622Z",
     "iopub.status.idle": "2022-05-17T03:04:38.726969Z",
     "shell.execute_reply": "2022-05-17T03:04:38.726017Z",
     "shell.execute_reply.started": "2022-05-17T02:47:48.230811Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tar -xf data/data142446/watermark_datasets.part1.tar\n",
    "!rm data/data142446/watermark_datasets.part1.tar\n",
    "!cp -r watermark_datasets.part1 -d data/train/image\n",
    "!rm -r watermark_datasets.part1/\n",
    "! tar -xf data/data142446/watermark_datasets.part2.tar\n",
    "!rm data/data142446/watermark_datasets.part2.tar\n",
    "!cp -r watermark_datasets.part2 -d data/train/image\n",
    "!rm -r watermark_datasets.part2/\n",
    "! tar -xf data/data142446/watermark_datasets.part3.tar\n",
    "!rm data/data142446/watermark_datasets.part3.tar\n",
    "!cp -r watermark_datasets.part3 -d data/train/image\n",
    "!rm -r watermark_datasets.part3/\n",
    "! tar -xf data/data142446/watermark_datasets.part10.tar\n",
    "!rm data/data142446/watermark_datasets.part10.tar\n",
    "!cp -r watermark_datasets.part10 -d data/train/image\n",
    "!rm -r watermark_datasets.part10/\n",
    "! tar -xf data/data142446/bg_images.tar\n",
    "!rm data/data142446/bg_images.tar\n",
    "!cp -r bg_images -d data/train/mask/\n",
    "!rm -r bg_images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据读取器\n",
    "通过paddle.io.dataset构造读取器，便于读取数据。\n",
    "\n",
    "数据预处理包括：\n",
    "1. 将带有水印和不带水印的图片均转化为(3,512,512)的形状\n",
    "2. 对图片进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:31:57.790796Z",
     "iopub.status.busy": "2022-05-17T12:31:57.789414Z",
     "iopub.status.idle": "2022-05-17T12:31:58.818289Z",
     "shell.execute_reply": "2022-05-17T12:31:58.817378Z",
     "shell.execute_reply.started": "2022-05-17T12:31:57.790736Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data num: 405020, train num: 398944, val_num: 6076\n"
     ]
    }
   ],
   "source": [
    "#划分训练集及验证集\n",
    "import os\n",
    "watermark_dir = \"data/train/image\"\n",
    "bg_dir = \"data/train/mask/bg_images\"\n",
    "watermark_sub_dir = list(os.listdir(watermark_dir))\n",
    "all_watermark_list = []\n",
    "for sub_dir in watermark_sub_dir:\n",
    "    images_path = list(os.listdir(os.path.join(watermark_dir, sub_dir)))\n",
    "    for path in images_path:\n",
    "        if 'jpg' in path:\n",
    "            all_watermark_list.append(os.path.join(sub_dir, path))\n",
    "\n",
    "all_gt_list = list(os.listdir(bg_dir))\n",
    "train_ratio = 0.985\n",
    "all_watermark_list = sorted(all_watermark_list)\n",
    "\n",
    "train_len = int(train_ratio*len(all_watermark_list))\n",
    "train_data_list = all_watermark_list[:train_len]\n",
    "val_data_list = all_watermark_list[train_len:]\n",
    "print(\"total data num: {}, train num: {}, val_num: {}\".format(len(all_watermark_list), len(train_data_list), len(val_data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:32:00.413334Z",
     "iopub.status.busy": "2022-05-17T12:32:00.412121Z",
     "iopub.status.idle": "2022-05-17T12:32:02.281280Z",
     "shell.execute_reply": "2022-05-17T12:32:02.280527Z",
     "shell.execute_reply.started": "2022-05-17T12:32:00.413288Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "class MyDateset(paddle.io.Dataset):\n",
    "    def __init__(self, mode = 'train', train_list=None, watermark_dir=None, bg_dir=None, data_transform=None):\n",
    "        super(MyDateset, self).__init__()\n",
    "\n",
    "        self.mode = mode \n",
    "        self.watermark_dir = watermark_dir\n",
    "        self.bg_dir = bg_dir\n",
    "        self.data_transform = data_transform\n",
    "\n",
    "        self.train_list = train_list\n",
    "        print(len(self.train_list))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.train_list[index]\n",
    "        \n",
    "        bg_item = item.split('/')[1][:14]+'.jpg'\n",
    "\n",
    "        img = cv2.imread(os.path.join(self.watermark_dir, item))\n",
    "        label = cv2.imread(os.path.join(self.bg_dir, bg_item))\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img = paddle.vision.transforms.resize(img, (512,512), interpolation='bilinear')\n",
    "        label = paddle.vision.transforms.resize(label, (512,512), interpolation='bilinear')\n",
    "\n",
    "        img = img.transpose((2,0,1))\n",
    "        label = label.transpose((2,0,1))\n",
    "        \n",
    "        img = img/255\n",
    "        label = label/255\n",
    "\n",
    "        img = paddle.to_tensor(img).astype('float32')\n",
    "        label = paddle.to_tensor(label).astype('float32')\n",
    "\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络结构\n",
    "\n",
    "我们将Baseline的UNet模型做了四处修改：第一、我们选择使用leaky_relu，而不是relu，以尽可能的保留像素信息；第二、在Encoder与Decoder中间的过渡层，我们不是使用原来的单分支，而是以注意力为权重，建立双分支通路，将自适应加权结果变换后输入到Decoder中，增强模型容量；第三、同样地，水印输出，我们选择双分支输出，以注意力值为权重，增强样本适应性；第四，我们引入网络输入与输出之间的残差连接，着重于网络学习真实图片与水印图片之间的差异，加快了模型收敛。因此在一个压缩包的数据训练下，我们从A榜的0.58307提升到了0.61742。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:32:02.788642Z",
     "iopub.status.busy": "2022-05-17T12:32:02.788322Z",
     "iopub.status.idle": "2022-05-17T12:32:02.816697Z",
     "shell.execute_reply": "2022-05-17T12:32:02.815982Z",
     "shell.execute_reply.started": "2022-05-17T12:32:02.788613Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle import nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "class CALayer(nn.Layer):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(CALayer, self).__init__()\n",
    "\n",
    "        mid_c = max(channels//reduction, 16)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2D(channels, mid_c, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(mid_c, channels, 1),\n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.mean(axis=(-1, -2), keepdim=True)\n",
    "        y = self.conv1(y)\n",
    "        return y\n",
    "\n",
    "class Encoder(nn.Layer):#下采样：两层卷积，两层归一化，最后池化。\n",
    "    def __init__(self, num_channels, num_filters):\n",
    "        super(Encoder,self).__init__()#继承父类的初始化\n",
    "        self.conv1 = nn.Conv2D(in_channels=num_channels,\n",
    "                              out_channels=num_filters,\n",
    "                              kernel_size=3,#3x3卷积核，步长为1，填充为1，不改变图片尺寸[H W]\n",
    "                              stride=1,\n",
    "                              padding=1,\n",
    "                              bias_attr=False)\n",
    "        self.bn1   = nn.BatchNorm(num_filters)#归一化，并使用了激活函数\n",
    "        \n",
    "        self.conv2 = nn.Conv2D(in_channels=num_filters,\n",
    "                              out_channels=num_filters,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1,\n",
    "                              bias_attr=False)\n",
    "        self.bn2   = nn.BatchNorm(num_filters)\n",
    "        \n",
    "        self.pool  = nn.MaxPool2D(kernel_size=2,stride=2,padding=\"SAME\")#池化层，图片尺寸减半[H/2 W/2]\n",
    "\n",
    "        if num_channels!=num_filters:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2D(num_channels, num_filters, 1, bias_attr=False),\n",
    "                nn.BatchNorm2D(num_filters)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x+self.downsample(inputs), 0.2)\n",
    "        x_conv = x           #两个输出，灰色 ->\n",
    "        x_pool = self.pool(x)#两个输出，红色 | \n",
    "        return x_conv, x_pool\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Layer):#上采样：一层反卷积，两层卷积层，两层归一化\n",
    "    def __init__(self, num_channels, num_filters):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.up = nn.Conv2DTranspose(in_channels=num_channels,\n",
    "                                    out_channels=num_filters,\n",
    "                                    kernel_size=2,\n",
    "                                    stride=2,\n",
    "                                    padding=0,\n",
    "                                    bias_attr=False)#图片尺寸变大一倍[2*H 2*W]\n",
    "        self.up_bn   = nn.BatchNorm(num_filters)\n",
    "\n",
    "        self.conv1 = nn.Conv2D(in_channels=num_filters*2,\n",
    "                              out_channels=num_filters,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1,\n",
    "                              bias_attr=False)\n",
    "        self.bn1   = nn.BatchNorm(num_filters)\n",
    "        \n",
    "        self.conv2 = nn.Conv2D(in_channels=num_filters,\n",
    "                              out_channels=num_filters,\n",
    "                              kernel_size=3,\n",
    "                              stride=1,\n",
    "                              padding=1,\n",
    "                              bias_attr=False)\n",
    "        self.bn2   = nn.BatchNorm(num_filters)\n",
    "\n",
    "        if num_channels!=num_filters:\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Conv2D(num_filters*2, num_filters, 1, bias_attr=False),\n",
    "                nn.BatchNorm2D(num_filters)\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = lambda x: x\n",
    "        \n",
    "    def forward(self,input_conv,input_pool):\n",
    "        x = self.up_bn(self.up(input_pool))\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        h_diff = (input_conv.shape[2]-x.shape[2])\n",
    "        w_diff = (input_conv.shape[3]-x.shape[3])\n",
    "        pad = nn.Pad2D(padding=[h_diff//2, h_diff-h_diff//2, w_diff//2, w_diff-w_diff//2])\n",
    "        x = pad(x)                                #以下采样保存的feature map为基准，填充上采样的feature map尺寸\n",
    "        x = paddle.concat(x=[input_conv,x],axis=1)#考虑上下文信息，in_channels扩大两倍\n",
    "        x_sc = self.upsample(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x+x_sc, 0.2)\n",
    "        return x\n",
    "    \n",
    "class UNet(nn.Layer):\n",
    "    def __init__(self,num_classes=3):\n",
    "        super(UNet,self).__init__()\n",
    "        self.down1 = Encoder(num_channels=  3, num_filters=64) #下采样\n",
    "        self.down2 = Encoder(num_channels= 64, num_filters=128)\n",
    "        self.down3 = Encoder(num_channels=128, num_filters=256)\n",
    "        self.down4 = Encoder(num_channels=256, num_filters=512)\n",
    "        \n",
    "        self.mid_conv1 = nn.Sequential(\n",
    "            nn.Conv2D(512,1024,1, bias_attr=False),\n",
    "            nn.BatchNorm(1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.mid_conv2 = nn.Sequential(\n",
    "            nn.Conv2D(512,1024,3, padding=1, bias_attr=False),\n",
    "            nn.BatchNorm(1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.ca_layer1 = CALayer(1024, 32)\n",
    "\n",
    "        self.mid_conv3 = nn.Sequential(\n",
    "            nn.Conv2D(1024,1024,1, bias_attr=False),\n",
    "            nn.BatchNorm(1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.up4 = Decoder(1024,512)                           #上采样\n",
    "        self.up3 = Decoder(512,256)\n",
    "        self.up2 = Decoder(256,128)\n",
    "        self.up1 = Decoder(128,64)\n",
    "        \n",
    "        self.last_conv1 = nn.Conv2D(64,num_classes,1)           #1x1卷积，softmax做分类\n",
    "        self.last_conv2 = nn.Conv2D(64,num_classes,3, padding=1)\n",
    "\n",
    "        self.ca_layer2 = CALayer(num_classes)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x1, x = self.down1(inputs)\n",
    "        x2, x = self.down2(x)\n",
    "        x3, x = self.down3(x)\n",
    "        x4, x = self.down4(x)\n",
    "        \n",
    "        x_m1 = self.mid_conv1(x)\n",
    "        x_m2 = self.mid_conv2(x)\n",
    "        attn = self.ca_layer1(x_m1+x_m2)\n",
    "        x = x_m1*attn+x_m2*(1.-attn)\n",
    "        x = self.mid_conv3(x)\n",
    "        \n",
    "        x = self.up4(x4, x)\n",
    "        x = self.up3(x3, x)\n",
    "        x = self.up2(x2, x)\n",
    "        x = self.up1(x1, x)\n",
    "        \n",
    "        out1 = self.last_conv1(x)\n",
    "        out2 = self.last_conv2(x)\n",
    "        attn = self.ca_layer2(out1+out2)\n",
    "        x = out1*attn+out2*(1.-attn)\n",
    "        \n",
    "        return inputs-x\n",
    "\n",
    "# 查看网络各个节点的输出信息\n",
    "#paddle.summary(UNet(), (1, 3, 600, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = UNet()\n",
    "train_dataset = MyDateset(train_list=train_data_list, watermark_dir=watermark_dir, bg_dir=bg_dir)\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    drop_last=False)\n",
    "for data in train_loader:\n",
    "    img, label = data\n",
    "    pred = net(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义loss\n",
    "同样秉承着拿来主义的思想，从[图像评价指标PSNR、SSIM以及MS-SSIM\n",
    "](https://aistudio.baidu.com/aistudio/projectdetail/1844007?channelType=0&channel=0)复制一份MSSSIM代码过来。\n",
    "\n",
    "~看不看得懂代码不重要，重要是看得懂文字，明白大佬已经写好了一个现成的直接调用的loss函数~\n",
    "\n",
    "当然，仅有MSSSIM是不够的，还可以再根据[通过Sub-Pixel实现图像超分辨率](https://www.paddlepaddle.org.cn/documentation/docs/zh/practices/cv/super_resolution_sub_pixel.html#sub-pixel)写一个PSNR的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:32:11.518029Z",
     "iopub.status.busy": "2022-05-17T12:32:11.517693Z",
     "iopub.status.idle": "2022-05-17T12:32:11.557904Z",
     "shell.execute_reply": "2022-05-17T12:32:11.557163Z",
     "shell.execute_reply.started": "2022-05-17T12:32:11.517998Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "def gaussian1d(window_size, sigma):\n",
    "    ###window_size = 11\n",
    "    x = paddle.arange(window_size,dtype='float32')\n",
    "    x = x - window_size//2\n",
    "    gauss = paddle.exp(-x ** 2 / float(2 * sigma ** 2))\n",
    "    # print('gauss.size():', gauss.size())\n",
    "    ### torch.Size([11])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, sigma, channel):\n",
    "    _1D_window = gaussian1d(window_size, sigma).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).unsqueeze(0).unsqueeze(0)\n",
    "    # print('2d',_2D_window.shape)\n",
    "    # print(window_size, sigma, channel)\n",
    "    return _2D_window.expand([channel,1,window_size,window_size])\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel=3 ,data_range = 255.,size_average=True,C=None):\n",
    "    # size_average for different channel\n",
    "\n",
    "    padding = window_size // 2\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padding, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padding, groups=channel)\n",
    "    # print(mu1.shape)\n",
    "    # print(mu1[0,0])\n",
    "    # print(mu1.mean())\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padding, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padding, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padding, groups=channel) - mu1_mu2\n",
    "    if C ==None:\n",
    "        C1 = (0.01*data_range) ** 2\n",
    "        C2 = (0.03*data_range) ** 2\n",
    "    else:\n",
    "        C1 = (C[0]*data_range) ** 2\n",
    "        C2 = (C[1]*data_range) ** 2\n",
    "    # l = (2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1)\n",
    "    # ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    sc = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    lsc = ((2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1))*sc\n",
    "\n",
    "    if size_average:\n",
    "        ### ssim_map.mean()是对这个tensor里面的所有的数值求平均\n",
    "        return lsc.mean()\n",
    "    else:\n",
    "        # ## 返回各个channel的值\n",
    "        return lsc.flatten(2).mean(-1),sc.flatten(2).mean(-1)\n",
    "\n",
    "def ms_ssim(\n",
    "    img1, img2,window, data_range=255, size_average=True, window_size=11, channel=3, sigma=1.5, weights=None, C=(0.01, 0.03)\n",
    "):\n",
    "\n",
    "    r\"\"\" interface of ms-ssim\n",
    "    Args:\n",
    "        img1 (torch.Tensor): a batch of images, (N,C,[T,]H,W)\n",
    "        img2 (torch.Tensor): a batch of images, (N,C,[T,]H,W)\n",
    "        data_range (float or int, optional): value range of input images. (usually 1.0 or 255)\n",
    "        size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "        win_size: (int, optional): the size of gauss kernel\n",
    "        win_sigma: (float, optional): sigma of normal distribution\n",
    "        win (torch.Tensor, optional): 1-D gauss kernel. if None, a new kernel will be created according to win_size and win_sigma\n",
    "        weights (list, optional): weights for different levels\n",
    "        K (list or tuple, optional): scalar constants (K1, K2). Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.\n",
    "    Returns:\n",
    "        torch.Tensor: ms-ssim results\n",
    "    \"\"\"\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError(\"Input images should have the same dimensions.\")\n",
    "\n",
    "    # for d in range(len(img1.shape) - 1, 1, -1):\n",
    "    #     img1 = img1.squeeze(dim=d)\n",
    "    #     img2 = img2.squeeze(dim=d)\n",
    "\n",
    "    if not img1.dtype == img2.dtype:\n",
    "        raise ValueError(\"Input images should have the same dtype.\")\n",
    "\n",
    "    if len(img1.shape) == 4:\n",
    "        avg_pool = F.avg_pool2d\n",
    "    elif len(img1.shape) == 5:\n",
    "        avg_pool = F.avg_pool3d\n",
    "    else:\n",
    "        raise ValueError(f\"Input images should be 4-d or 5-d tensors, but got {img1.shape}\")\n",
    "\n",
    "    smaller_side = min(img1.shape[-2:])\n",
    "\n",
    "    assert smaller_side > (window_size - 1) * (2 ** 4), \"Image size should be larger than %d due to the 4 downsamplings \" \\\n",
    "                                                        \"with window_size %d in ms-ssim\" % ((window_size - 1) * (2 ** 4),window_size)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = [0.0448, 0.2856, 0.3001, 0.2363, 0.1333]\n",
    "    weights = paddle.to_tensor(weights)\n",
    "\n",
    "    if window is None:\n",
    "        window = create_window(window_size, sigma, channel)\n",
    "    assert window.shape == [channel, 1, window_size, window_size], \" window.shape error\"\n",
    "\n",
    "    levels = weights.shape[0] # 5\n",
    "    mcs = []\n",
    "    for i in range(levels):\n",
    "        ssim_per_channel, cs =  _ssim(img1, img2, window=window, window_size=window_size,\n",
    "                                       channel=3, data_range=data_range,C=C, size_average=False)\n",
    "        if i < levels - 1:\n",
    "            mcs.append(F.relu(cs))\n",
    "            padding = [s % 2 for s in img1.shape[2:]]\n",
    "            img1 = avg_pool(img1, kernel_size=2, padding=padding)\n",
    "            img2 = avg_pool(img2, kernel_size=2, padding=padding)\n",
    "\n",
    "    ssim_per_channel = F.relu(ssim_per_channel)  # (batch, channel)\n",
    "    mcs_and_ssim = paddle.stack(mcs + [ssim_per_channel], axis=0)  # (level, batch, channel) 按照等级堆叠\n",
    "    ms_ssim_val = paddle.prod(mcs_and_ssim ** weights.reshape([-1, 1, 1]), axis=0) # level 相乘\n",
    "    print(ms_ssim_val.shape)\n",
    "    if size_average:\n",
    "        return ms_ssim_val.mean()\n",
    "    else:\n",
    "        # 返回各个channel的值\n",
    "        return ms_ssim_val.flatten(2).mean(1)\n",
    "\n",
    "\n",
    "class SSIMLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self, window_size=11, channel=3, data_range=255., sigma=1.5):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(SSIMLoss, self).__init__()\n",
    "       self.data_range = data_range\n",
    "       self.C = [0.01, 0.03]\n",
    "       self.window_size = window_size\n",
    "       self.channel = channel\n",
    "       self.sigma = sigma\n",
    "       self.window = create_window(self.window_size, self.sigma, self.channel)\n",
    "       # print(self.window_size,self.window.shape)\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output\n",
    "       return 1-_ssim(input, label,data_range = self.data_range,\n",
    "                      window = self.window, window_size=self.window_size, channel=3,\n",
    "                      size_average=True,C=self.C)\n",
    "\n",
    "class MS_SSIMLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self,data_range=255., channel=3, window_size=11, sigma=1.5):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(MS_SSIMLoss, self).__init__()\n",
    "       self.data_range = data_range\n",
    "       self.C = [0.01, 0.03]\n",
    "       self.window_size = window_size\n",
    "       self.channel = channel\n",
    "       self.sigma = sigma\n",
    "       self.window = create_window(self.window_size, self.sigma, self.channel)\n",
    "       # print(self.window_size,self.window.shape)\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output\n",
    "       return 1-ms_ssim(input, label, data_range=self.data_range,\n",
    "                      window = self.window, window_size=self.window_size, channel=self.channel,\n",
    "                      size_average=True,  sigma=self.sigma,\n",
    "                      weights=None, C=self.C)\n",
    "\n",
    "class PSNRLoss(paddle.nn.Layer):\n",
    "   def __init__(self):\n",
    "       super(PSNRLoss, self).__init__()\n",
    "\n",
    "   def forward(self, input, label):\n",
    "       return 100 - 20 * paddle.log10( ((input - label)**2).mean(axis = [1,2,3])**-0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:32:13.921705Z",
     "iopub.status.busy": "2022-05-17T12:32:13.920542Z",
     "iopub.status.idle": "2022-05-17T12:32:13.925623Z",
     "shell.execute_reply": "2022-05-17T12:32:13.925043Z",
     "shell.execute_reply.started": "2022-05-17T12:32:13.921665Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_paddle(seed=1024):\n",
    "    seed = int(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    paddle.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:32:15.961224Z",
     "iopub.status.busy": "2022-05-17T12:32:15.960479Z",
     "iopub.status.idle": "2022-05-17T12:32:15.970991Z",
     "shell.execute_reply": "2022-05-17T12:32:15.970292Z",
     "shell.execute_reply.started": "2022-05-17T12:32:15.961179Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stor|es the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def evaluate(val_loader, model, criterion, print_interval=100):\n",
    "    losses = AverageMeter()\n",
    "    psnr = AverageMeter()\n",
    "    ssim = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    lossfn, losspsnr = criterion\n",
    "    for step, data in enumerate(val_loader):\n",
    "\n",
    "        img, label = data\n",
    "        end = time.time()\n",
    "        pre = model(img)\n",
    "        batch_time.update(time.time() - end)\n",
    "        loss1 = lossfn(pre,label).mean()\n",
    "        loss2 = losspsnr(pre,label).mean()\n",
    "        loss = (loss1+loss2/100)/2\n",
    "\n",
    "        losses.update(loss.item(), img.shape[0])\n",
    "        psnr.update(100.-loss2.item(), img.shape[0])\n",
    "        ssim.update(1.-loss1.item(), img.shape[0])\n",
    "        if step%print_interval==0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                'SSIM {ssim.val:.3f} ({ssim.avg:.3f})\\t'\n",
    "                'PSNR {psnr.val:.3f} ({psnr.avg:.3f})'.format(\n",
    "                step,\n",
    "                len(val_loader),\n",
    "                batch_time=batch_time,\n",
    "                loss=losses,\n",
    "                ssim=ssim,\n",
    "                psnr=psnr))\n",
    "\n",
    "    print(' * SSIM {ssim.avg:.3f} PSNR {psnr.avg:.3f} Time {batch_time.avg:.3f}'\n",
    "            .format(ssim=ssim, psnr=psnr, batch_time=batch_time))\n",
    "\n",
    "    return losses.avg, ssim.avg, psnr.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:32:17.970769Z",
     "iopub.status.busy": "2022-05-17T12:32:17.970226Z",
     "iopub.status.idle": "2022-05-17T12:32:17.975794Z",
     "shell.execute_reply": "2022-05-17T12:32:17.975070Z",
     "shell.execute_reply.started": "2022-05-17T12:32:17.970721Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "max_epoch = 10\n",
    "init_lr = 0.005\n",
    "print_interval = 100\n",
    "val_interval = 1\n",
    "save_dir = \"models/output\"\n",
    "save_interval = 1\n",
    "save_interval_s = 8000\n",
    "\n",
    "start_epoch = 0\n",
    "start_step = 0\n",
    "init_loss = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T12:33:11.765430Z",
     "iopub.status.busy": "2022-05-17T12:33:11.764861Z",
     "iopub.status.idle": "2022-05-17T12:33:12.007582Z",
     "shell.execute_reply": "2022-05-17T12:33:12.006617Z",
     "shell.execute_reply.started": "2022-05-17T12:33:11.765391Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398944\n",
      "6076\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "from visualdl import LogWriter\n",
    "\n",
    "model = UNet()\n",
    "model.train()\n",
    "\n",
    "train_dataset = MyDateset(train_list=train_data_list, watermark_dir=watermark_dir, bg_dir=bg_dir)\n",
    "val_dataset = MyDateset(train_list=val_data_list, watermark_dir=watermark_dir, bg_dir=bg_dir)\n",
    "\n",
    "# 需要接续之前的模型重复训练可以取消注释\n",
    "if start_epoch>0:\n",
    "    #param_dict = paddle.load(os.path.join(save_dir, 'model_step_{}.pdparams'.format(str(start_step))))\n",
    "    param_dict = paddle.load(os.path.join(save_dir, 'model_{}.pdparams'.format(str(start_epoch-1))))\n",
    "    model.set_state_dict(param_dict)\n",
    "\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False)\n",
    "\n",
    "val_loader = paddle.io.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False)\n",
    "\n",
    "losspsnr = PSNRLoss()\n",
    "lossfn = SSIMLoss(window_size=3,data_range=1)\n",
    "\n",
    "scheduler = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=init_lr, T_max=max_epoch)\n",
    "opt = paddle.optimizer.Adam(learning_rate=scheduler, parameters=model.parameters())\n",
    "\n",
    "if start_epoch>0:\n",
    "    pass\n",
    "    #param_dict = paddle.load(os.path.join(save_dir, 'opt_step_{}.pdopt'.format(str(start_step))))\n",
    "    param_dict = paddle.load(os.path.join(save_dir, 'opt_{}.pdopt'.format(str(start_epoch-1))))\n",
    "    opt.set_state_dict(param_dict)\n",
    "\n",
    "writer = LogWriter(os.path.join(save_dir, \"logs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "now_step = start_epoch*len(train_loader)\n",
    "min_loss = init_loss\n",
    "for epoch in range(start_epoch, max_epoch):\n",
    "    losses = AverageMeter()\n",
    "    psnr = AverageMeter()\n",
    "    ssim = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    end = time.time()\n",
    "    for step, data in enumerate(train_loader):\n",
    "\n",
    "        if epoch==start_epoch and step>=((start_epoch+1)*len(train_loader)-now_step):\n",
    "            #print(step+start_epoch*len(train_loader))\n",
    "            break\n",
    "\n",
    "        img, label = data\n",
    "        data_time.update(time.time() - end)\n",
    "        pre = model(img)\n",
    "        loss1 = lossfn(pre,label).mean()\n",
    "        loss2 = losspsnr(pre,label).mean()\n",
    "        loss = (loss1+loss2/100)/2\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_gradients()\n",
    "\n",
    "        losses.update(loss.item(), img.shape[0])\n",
    "        psnr.update(100.-loss2.item(), img.shape[0])\n",
    "        ssim.update(1.-loss1.item(), img.shape[0])\n",
    "        batch_time.update(time.time() - end)\n",
    "        \n",
    "        if now_step%print_interval==0:\n",
    "            writer.add_scalar('train/loss', losses.val, now_step)\n",
    "            writer.add_scalar('train/ssim', ssim.val, now_step)\n",
    "            writer.add_scalar('train/psnr', psnr.val, now_step)\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'SSIM {ssim.val:.3f} ({ssim.avg:.3f})\\t'\n",
    "                  'PSNR {psnr.val:.3f} ({psnr.avg:.3f})'.format(\n",
    "                    epoch,\n",
    "                    step,\n",
    "                    len(train_loader),\n",
    "                    batch_time=batch_time,\n",
    "                    data_time=data_time,\n",
    "                    loss=losses,\n",
    "                    ssim=ssim,\n",
    "                    psnr=psnr))\n",
    "\n",
    "        if now_step%save_interval_s==0:\n",
    "            paddle.save(model.state_dict(), os.path.join(save_dir, 'model_step_{}.pdparams'.format(str(now_step))))\n",
    "            paddle.save(opt.state_dict(), os.path.join(save_dir, 'opt_step_{}.pdopt'.format(str(now_step))))\n",
    "        now_step += 1\n",
    "        end = time.time()\n",
    "\n",
    "    writer.add_scalar('train/lr', opt.get_lr(), epoch)\n",
    "    scheduler.step()\n",
    "    if epoch%val_interval==0:\n",
    "        with paddle.no_grad():\n",
    "            model.eval()\n",
    "            val_loss, val_ssim, val_psnr = evaluate(val_loader, model, criterion=(lossfn, losspsnr), print_interval=print_interval)\n",
    "            model.train()\n",
    "            writer.add_scalar('val/loss', val_loss, epoch)\n",
    "            writer.add_scalar('val/ssim', val_ssim, epoch)\n",
    "            writer.add_scalar('val/psnr', val_psnr, epoch)\n",
    "        if val_loss<min_loss:\n",
    "            min_loss = val_loss\n",
    "            paddle.save(model.state_dict(), os.path.join(save_dir, 'model_best.pdparams'))\n",
    "    if epoch%save_interval==0:\n",
    "        paddle.save(model.state_dict(), os.path.join(save_dir, 'model_{}.pdparams'.format(str(epoch))))\n",
    "        paddle.save(opt.state_dict(), os.path.join(save_dir, 'opt_{}.pdopt'.format(str(epoch))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打包提交\n",
    "本题目提交需要提交对应的模型和预测文件。predict.py需要读取同目录下的模型信息，预测去水印后的图片并保存。\n",
    "\n",
    "想要自定义训练模型，只需要将predict.py中的模型和process函数中的do something 替换为自己的模型内容即可。\n",
    "\n",
    "Baseline说：直接用UNet处理的结果可能不够理想，并非所有的情况都需要通过修正网络来解决。以下述情况为例，把在某个阈值内的颜色都设定为黑色（字的颜色）/白色（背景的颜色），可以让处理结果更契合人眼的需求。在predict.py中已经通过以下语句包含了这样的处理策略：\n",
    "```\n",
    "pre[pre>0.9]=1\n",
    "pre[pre<0.1]=0\n",
    "```\n",
    "但我们去除了这个策略，因为我们A榜分数发现，去除后分数从0.61805升到0.61919。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-25T12:29:40.243625Z",
     "iopub.status.busy": "2022-05-25T12:29:40.242606Z",
     "iopub.status.idle": "2022-05-25T12:29:45.190820Z",
     "shell.execute_reply": "2022-05-25T12:29:45.189742Z",
     "shell.execute_reply.started": "2022-05-25T12:29:40.243565Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model_best.pdparams (deflated 7%)\n",
      "  adding: predict.py (deflated 72%)\n"
     ]
    }
   ],
   "source": [
    "# 压缩可提交文件\n",
    "! zip submit_removal.zip model_best.pdparams predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看预测结果（可选、非常耗时）\n",
    "是不是想知道自己训练后的网络去除水印之后的图片到底长啥样？直接下载测试集A看看效果吧~\n",
    "\n",
    "### 下载测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://staticsns.cdn.bcebos.com/amis/2022-4/1649745356784/watermark_test_datasets.zip\n",
    "! unzip -oq watermark_test_datasets.zip\n",
    "! rm -rf watermark_test_datasets.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在测试集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python predict.py watermark_test_datasets/images results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测结束之后，打开results文件夹就能看到去除水印的图片了~\n",
    "\n",
    "以图片bg_image_00005_0002.jpg为例\n",
    "\n",
    "\n",
    "| with watermask | without watermask |\n",
    "| -------- | -------- |\n",
    "|  ![](https://ai-studio-static-online.cdn.bcebos.com/171fc00c9d8c43438fa2935f5239546daa29140cc0a64cfa80a8af066c78e7f6)   | ![](https://ai-studio-static-online.cdn.bcebos.com/dc81d9daf2fb4ec789aa43cf29e6c1633a466fa3d0ea4e14b289c3ad2efb8cb4)    |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 总结\n",
    "\n",
    "本项目使用极简的方式完成了百度网盘AI大赛-图像处理挑战赛：水印智能消除赛。项目有极大的改进的空间。比如：\n",
    "\n",
    "1. 本项目使用了修改后的UNet网络，但在image2image任务上有其他策略可以选择，比如IDR网络。\n",
    "2. 本项目使用用PSNR和MSSSIM作为混合loss，可以设计更合理的指标用于训练。\n",
    "3. 本项目resize图片为512x512,导致图片损失大量信息,可以考虑对图片进行补零，从而尽可能贴近原图的尺寸进行预测。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
